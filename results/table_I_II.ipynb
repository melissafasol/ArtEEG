{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e57dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir('/home/melissa/PROJECT_DIRECTORIES/EEGFeatureExtraction/Scripts/Preprocessing/')\n",
    "%run sleep_score_gmm.py\n",
    "%run load_files.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "553e52d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = ['S7068',  'S7070', 'S7071', 'S7074']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb40646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S7068\n",
      "noisy epochs\n",
      "[0 1 2]\n",
      "[1632  984   78]\n",
      "clean epochs\n",
      "[0 1 2]\n",
      "[6898 6390  324]\n",
      "S7070\n",
      "noisy epochs\n",
      "[0 1 2]\n",
      "[1669  513  132]\n",
      "clean epochs\n",
      "[0 1 2]\n",
      "[6849 6527  956]\n",
      "S7071\n",
      "noisy epochs\n",
      "[0 1 2]\n",
      "[1585  268   71]\n",
      "clean epochs\n",
      "[0 1 2]\n",
      "[5970 7254 1197]\n",
      "S7074\n",
      "noisy epochs\n",
      "[0 1 2]\n",
      "[1682  343   21]\n",
      "clean epochs\n",
      "[0 1 2]\n",
      "[7013 5924  284]\n"
     ]
    }
   ],
   "source": [
    "train_ids_df = []\n",
    "directory_path = '/home/melissa/PREPROCESSING/SYNGAP1/numpyformat_baseline/'\n",
    "for animal in train_ids:\n",
    "    print(animal)\n",
    "    load_files = LoadFiles(directory_path, animal)\n",
    "    data_1, brain_state_1 = load_files.load_one_analysis_file(start_times_dict = SYNGAP_baseline_start, end_times_dict = SYNGAP_baseline_end)\n",
    "    noise_filter_1 = NoiseFilter(data_1, brain_state_file = brain_state_1, channelvariables = channel_variables,ch_type = 'all')\n",
    "    bandpass_filtered_data_1 = noise_filter_1.filter_data_type()\n",
    "    eeg_chan = np.split(bandpass_filtered_data_1[3], 17280, axis = 0)\n",
    "    packet_loss_dir = '/home/melissa/PREPROCESSING/SYNGAP1/cleaned_br_files/'\n",
    "    file_name = str(animal) + '_BL1.pkl'\n",
    "    packet_loss_indices = remove_typical_packet_loss(packet_loss_dir, file_name)\n",
    "    int_slope_dir = '/home/melissa/RESULTS/ICASSP/ALL_EPOCHS/Int_Slope/'\n",
    "    slope_df = pd.read_csv(int_slope_dir + str(animal) + '_br_1_all_epochs.csv')  \n",
    "    slope_identified_indices_df = slope_df.loc[slope_df['Slope'] < -8]\n",
    "    slope_identified_indices = np.unique(np.array(slope_identified_indices_df['Epoch']))\n",
    "    \n",
    "    #dictionary of animal ids of interest and corresponding column\n",
    "    column_dict = {'S7068': 'AG', 'S7070': 'AU', 'S7071': 'BB', 'S7074': 'BW'}\n",
    "    file_path = '/home/melissa/'\n",
    "    file_name = 'autoscorer_validation.xlsx'\n",
    "    vis_score = extract_sleep_stages(file_path, file_name, column_name = column_dict.get(animal))\n",
    "    sleep_stage_count = []\n",
    "    pass_indices = [0, 17279, 17280]\n",
    "    clean_indices = []\n",
    "    for idx in slope_identified_indices:\n",
    "        if idx in pass_indices:\n",
    "            pass\n",
    "        elif idx + 1 in slope_identified_indices:\n",
    "            pass\n",
    "        else:\n",
    "            prev_idx = idx - 1 \n",
    "            next_idx = idx + 1\n",
    "            sleep_stage_count.append(vis_score[prev_idx])\n",
    "            sleep_stage_count.append(vis_score[next_idx])\n",
    "    \n",
    "    for idx in np.arange(0, 17280, 1):\n",
    "        if idx not in slope_identified_indices:\n",
    "            clean_indices.append(vis_score[idx])\n",
    "    \n",
    "    stage_unique, stage_counts = np.unique(sleep_stage_count, return_counts=True)\n",
    "    print('noisy epochs')\n",
    "    print(stage_unique)\n",
    "    print(stage_counts)\n",
    "    \n",
    "    clean_unique, clean_counts = np.unique(clean_indices, return_counts=True)\n",
    "    print('clean epochs')\n",
    "    print(clean_unique)\n",
    "    print(clean_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53125a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2023",
   "language": "python",
   "name": "env2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
